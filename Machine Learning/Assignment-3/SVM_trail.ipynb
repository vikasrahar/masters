{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "Load the data set into Python using, e.g., load_wine or genfromtxt, as appropriate. In the case of the USPS dataset, merge the original training and test sets into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPS_test=np.genfromtxt(\"zip.test\")\n",
    "USPS_train=np.genfromtxt(\"zip.train\")\n",
    "USPS=np.concatenate((USPS_train,USPS_test),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Divide the dataset into a training set and a test set. You may use the function train_test_split. Use your birthday in the format DDMM as random_state (omit leading zeros if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wine=wine.data\n",
    "y_wine=wine.target\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine=train_test_split(X_wine,y_wine,random_state=206)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_USPS=USPS[:,:-1]\n",
    "y_USPS=USPS[:,-1].astype(int)\n",
    "X_train_USPS, X_test_USPS, y_train_USPS, y_test_USPS=train_test_split(X_USPS,y_USPS,random_state=206)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Using cross-validation and the training set only, estimate the generalization accuracy of the SVM with the default values of the parameters. You may use the function cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training set) of the SVM on winedata set with default values of parameters: 0.4289073750651102\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "scores_wine=cross_val_score(svm,X_train_wine,y_train_wine)\n",
    "accuracy_wine_train = np.mean(scores_wine)\n",
    "print('Accuracy (training set) of the SVM on winedata set with default values of parameters:',accuracy_wine_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training set) of the SVM on USPS dataset with default values of parameters: 0.9886705655186029\n"
     ]
    }
   ],
   "source": [
    "scores_USPS=cross_val_score(svm,X_train_USPS,y_train_USPS)\n",
    "accuracy_USPS_train = np.mean(scores_USPS)\n",
    "print('Accuracy (training set) of the SVM on USPS dataset with default values of parameters:',accuracy_USPS_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Find the test error rate of the SVM with the default values of parameters, compare it with the estimate obtained in the previous task (task 3), and write your observations in a markdown cell of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error Rate of the SVM: 0.6\n",
      "Accuracy on training set: 0.4289073750651102\n"
     ]
    }
   ],
   "source": [
    "svc_wine=SVC()\n",
    "svc_wine.fit(X_train_wine,y_train_wine)\n",
    "test_error_rate_wine=1-svc_wine.score(X_test_wine,y_test_wine)\n",
    "print('Test Error Rate of the SVM:',test_error_rate_wine)\n",
    "print('Accuracy on training set:',accuracy_wine_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error Rate of the SVM: 0.010322580645161339\n",
      "Accuracy on training set: 0.9886705655186029\n"
     ]
    }
   ],
   "source": [
    "svc_USPS=SVC()\n",
    "svc_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "test_error_rate_USPS=1-svc_USPS.score(X_test_USPS,y_test_USPS)\n",
    "print('Test Error Rate of the SVM:',test_error_rate_USPS)\n",
    "print('Accuracy on training set:',accuracy_USPS_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: It was observed that the result obtained for Accuracy on training set and test error rate on test dataset for both the datasets (Wine and USPS) are almost similar meaning that the model is underfitting where training and test performance is quite similar. The model can be improved by increasing the value of C and gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Create a pipeline for SVM involving data normalization and SVC, and use grid search and cross-validation to tune parameters C and gamma for the pipeline, avoiding data snooping and data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy on training dataset (MinMaxScaler): 0.9924812030075187\n",
      "Best cross-validation accuracy on training dataset(StandardScaler): 0.9924812030075187\n",
      "Best cross-validation accuracy on training dataset (RobustScaler): 0.9849624060150376\n",
      "Best cross-validation accuracy on training dataset(Normalizer): 0.9097744360902256\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100],'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#---- MinMaxScaler -------\n",
    "pipe_wine_MinMaxScaler = make_pipeline(MinMaxScaler(), SVC())\n",
    "grid_MinMaxScaler = GridSearchCV(pipe_wine_MinMaxScaler, param_grid=param_grid)\n",
    "grid_MinMaxScaler.fit(X_train_wine,y_train_wine)\n",
    "print(\"Best cross-validation accuracy on training dataset (MinMaxScaler):\", grid_MinMaxScaler.best_score_) \n",
    "\n",
    "#----- Standard Scaler --------\n",
    "pipe_wine_StandardScaler = make_pipeline(StandardScaler(), SVC())\n",
    "grid_StandardScaler = GridSearchCV(pipe_wine_StandardScaler, param_grid=param_grid)\n",
    "grid_StandardScaler.fit(X_train_wine,y_train_wine)\n",
    "print(\"Best cross-validation accuracy on training dataset(StandardScaler):\", grid_StandardScaler.best_score_) \n",
    "\n",
    "#------ RobustScaler ----------\n",
    "pipe_wine_RobustScaler = make_pipeline(RobustScaler(), SVC())\n",
    "grid_RobustScaler = GridSearchCV(pipe_wine_RobustScaler, param_grid=param_grid)\n",
    "grid_RobustScaler.fit(X_train_wine,y_train_wine)\n",
    "print(\"Best cross-validation accuracy on training dataset (RobustScaler):\", grid_RobustScaler.best_score_) \n",
    "\n",
    "#----- Normalizer ------------\n",
    "pipe_wine_Normalizer = make_pipeline(Normalizer(), SVC())\n",
    "grid_Normalizer = GridSearchCV(pipe_wine_Normalizer, param_grid=param_grid) \n",
    "grid_Normalizer.fit(X_train_wine,y_train_wine)\n",
    "print(\"Best cross-validation accuracy on training dataset(Normalizer):\", grid_Normalizer.best_score_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy on training dataset (MinMaxScaler): 0.9939767675319088\n",
      "Best cross-validation accuracy on training dataset(StandardScaler): 0.9954108705005019\n",
      "Best cross-validation accuracy on training dataset (RobustScaler): 0.9870930732826617\n",
      "Best cross-validation accuracy on training dataset(Normalizer): 0.9929728954538936\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.01, 1, 10],'svc__gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "#---- MinMaxScaler -------\n",
    "pipe_USPS_MinMaxScaler = make_pipeline(MinMaxScaler(), SVC())\n",
    "grid_MinMaxScaler_USPS = GridSearchCV(pipe_USPS_MinMaxScaler, param_grid=param_grid)\n",
    "grid_MinMaxScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "print(\"Best cross-validation accuracy on training dataset (MinMaxScaler):\", grid_MinMaxScaler_USPS.best_score_)  \n",
    "\n",
    "#----- Standard Scaler --------\n",
    "pipe_USPS_StandardScaler = make_pipeline(StandardScaler(), SVC())\n",
    "grid_StandardScaler_USPS = GridSearchCV(pipe_USPS_StandardScaler, param_grid=param_grid)\n",
    "grid_StandardScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "print(\"Best cross-validation accuracy on training dataset(StandardScaler):\", grid_StandardScaler_USPS.best_score_) \n",
    "\n",
    "#------ RobustScaler ----------\n",
    "pipe_USPS_RobustScaler = make_pipeline(RobustScaler(), SVC())\n",
    "grid_RobustScaler_USPS = GridSearchCV(pipe_wine_RobustScaler, param_grid=param_grid)\n",
    "grid_RobustScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "print(\"Best cross-validation accuracy on training dataset (RobustScaler):\", grid_RobustScaler_USPS.best_score_) \n",
    "\n",
    "#----- Normalizer ------------\n",
    "pipe_USPS_Normalizer = make_pipeline(Normalizer(), SVC())\n",
    "grid_Normalizer_USPS = GridSearchCV(pipe_USPS_Normalizer, param_grid=param_grid) \n",
    "grid_Normalizer_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "print(\"Best cross-validation accuracy on training dataset(Normalizer):\", grid_Normalizer_USPS.best_score_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Fit the GridSearchCV object of task 5 to the training set and use it to predict the test labels. Write the resulting test accuracy in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score (MinMaxScaler): 0.9777777777777777\n",
      "Test set score (StandardScaler): 1.0\n",
      "Test set score (RobustScaler): 0.9777777777777777\n",
      "Test set score (Normalizer): 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "grid_MinMaxScaler.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_MinMaxScaler=grid_MinMaxScaler.predict(X_test_wine)\n",
    "print(\"Test set score (MinMaxScaler):\", np.mean(y_test_wine==pred_wine_MinMaxScaler))\n",
    "\n",
    "grid_StandardScaler.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_StandardScaler=grid_StandardScaler.predict(X_test_wine)\n",
    "print(\"Test set score (StandardScaler):\", np.mean(y_test_wine==pred_wine_StandardScaler)) \n",
    "\n",
    "grid_RobustScaler.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_RobustScaler=grid_RobustScaler.predict(X_test_wine)\n",
    "print(\"Test set score (RobustScaler):\",np.mean(y_test_wine==pred_wine_RobustScaler)) \n",
    "\n",
    "grid_Normalizer.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_Normalizer=grid_Normalizer.predict(X_test_wine)\n",
    "print(\"Test set score (Normalizer):\",np.mean(y_test_wine==pred_wine_Normalizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization techiques used on Wine Data set were StandardScaler, MinMaxScaler, RobustScaler, and Normalizer.\n",
    "\n",
    "After training the dataset and testing it on different normalisation techniques, it was observed that for:\n",
    "1. MinMaxScaler: 0.9924812030075187 (training) and 0.9777777777777777 (test score) - The performance decreased.\n",
    "2. StandardScaler: 0.9924812030075187 (training) and 1.0 (test score) - The model overfitted\n",
    "3. RobustScaler: 0.9849624060150376 (training) and 0.9777777777777777 (test score) - The model performace decreased\n",
    "4. Normalizer: 0.9097744360902256 (training) and 0.9777777777777777 (test score) - The performace of the model increased.\n",
    "\n",
    "Hence, for wine dataset Normalizer is a better normalization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score (MinMaxScaler): 0.993978494623656\n",
      "Test set score (StandardScaler): 0.9969892473118279\n",
      "Test set score (RobustScaler): 0.9862365591397849\n",
      "Test set score (Normalizer): 0.9931182795698925\n"
     ]
    }
   ],
   "source": [
    "grid_MinMaxScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_MinMaxScaler=grid_MinMaxScaler_USPS.predict(X_test_USPS)\n",
    "print(\"Test set score (MinMaxScaler):\", np.mean(y_test_USPS==pred_USPS_MinMaxScaler))\n",
    "\n",
    "grid_StandardScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_StandardScaler=grid_StandardScaler_USPS.predict(X_test_USPS)\n",
    "print(\"Test set score (StandardScaler):\", np.mean(y_test_USPS==pred_USPS_StandardScaler)) \n",
    "\n",
    "grid_RobustScaler_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_RobustScaler=grid_RobustScaler_USPS.predict(X_test_USPS)\n",
    "print(\"Test set score (RobustScaler):\",np.mean(y_test_USPS==pred_USPS_RobustScaler)) \n",
    "\n",
    "grid_Normalizer_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_Normalizer=grid_Normalizer_USPS.predict(X_test_USPS)\n",
    "print(\"Test set score (Normalizer):\",np.mean(y_test_USPS==pred_USPS_Normalizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization techiques used on USPS Data set were StandardScaler, MinMaxScaler, RobustScaler, and Normalizer. \n",
    "\n",
    "After training the dataset and testing it on different normalisation techniques, it was observed that for:\n",
    "\n",
    "1. MinMaxScaler: 0.9939767675319088 (training) and 0.993978494623656 (test score) - The performance is underfitting.\n",
    "2. StandardScaler: 0.9954108705005019 (training) and 0.9969892473118279 (test score) - The model performance increased.\n",
    "3. RobustScaler: 0.9870930732826617 (training) and 0.9862365591397849 (test score) - The model performace decreased\n",
    "4. Normalizer: 0.9929728954538936 (training) and 0.9931182795698925 (test score) - The performace of the model is almost the same for training and test - underfitting.\n",
    "\n",
    "Hence, for USPS dataset StandardScaler is a better normalization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Implement a cross-conformal predictor. You may use the KFold class for splitting into folds (start from 5 or 10 folds). For computing the conformity scores for each fold, you may use one of the GridSearchCV objects that you created in task 5 in combination with the decision_function method (see Section 3 of Lab Worksheet 9 for examples). Run your cross-conformal predictor on the two datasets, training it on the training set and testing on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: An alternative to implementing a cross-conformal predictor is to experi- ment with a neural network. Perform tasks 3–6 for the scikit-learn class MLPClassifier, as described in Lab Worksheet 8, Section 1. It is up to you to decide which parameters to fit using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization accuracy (train) with MLP Classifier: 0.8723304838067224\n",
      "Generalizaton accuracy (training set) of the SVM on wine dataset (default parameters): 0.4289073750651102\n",
      "Test Error Rate (default parameters) with MLP Classifier: 0.13333333333333333\n",
      "Test Error Rate of the SVM: 0.4\n",
      "\n",
      "\n",
      "Test Error rate (MinMaxScaler) for classifier: 0.0\n",
      "Test Error rate (MinMaxScaler) for wine dataset (SVC): 0.022222222222222223\n",
      "\n",
      "\n",
      "Test Error rate (Normalizer) for classifier on wine dataset: 0.0\n",
      "Test Error rate (Normalizer) for wine dataset: 0.022222222222222223\n"
     ]
    }
   ],
   "source": [
    "mlp_wine=MLPClassifier(random_state=206)\n",
    "scores_wine_mlp=cross_val_score(mlp_wine,X_train_wine,y_train_wine)\n",
    "accuracy_wine_mlp = np.mean(scores_wine_mlp)\n",
    "print('Generalization accuracy (train) with MLP Classifier:',accuracy_wine_mlp)\n",
    "print('Generalizaton accuracy (training set) of the SVM on wine dataset (default parameters):',accuracy_wine_train)\n",
    "\n",
    "mlp_wine.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_mlp=mlp_wine.predict(X_test_wine)\n",
    "print('Test Error Rate (default parameters) with MLP Classifier:',np.mean(y_test_wine!=pred_wine_mlp))\n",
    "print('Test Error Rate of the SVM:',test_error_rate_wine)\n",
    "\n",
    "print('\\n')\n",
    "param_grid = {'mlpclassifier__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'mlpclassifier__hidden_layer_sizes': [[10],[10,10],[10,10,10]],\n",
    "              'mlpclassifier__activation':['relu','tanh']}\n",
    "\n",
    "#---- MinMaxScaler -------\n",
    "pipe_wine_mlp_MinMaxScaler = make_pipeline(MinMaxScaler(), mlp_wine)\n",
    "grid_MinMaxScaler_mlp = GridSearchCV(pipe_wine_mlp_MinMaxScaler, param_grid=param_grid)\n",
    "grid_MinMaxScaler_mlp.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_MinMaxScaler_mlp=grid_MinMaxScaler_mlp.predict(X_test_wine)\n",
    "print(\"Test Error rate (MinMaxScaler) for classifier:\", np.mean(y_test_wine!=pred_wine_MinMaxScaler_mlp))\n",
    "print(\"Test Error rate (MinMaxScaler) for wine dataset (SVC):\", np.mean(y_test_wine!=pred_wine_MinMaxScaler))\n",
    "print('\\n')\n",
    "\n",
    "#----- Normalizer ------------\n",
    "pipe_wine_Normalizer_mlp = make_pipeline(Normalizer(), mlp_wine)\n",
    "grid_Normalizer_mlp = GridSearchCV(pipe_wine_Normalizer_mlp, param_grid=param_grid) \n",
    "grid_Normalizer_mlp.fit(X_train_wine,y_train_wine)\n",
    "pred_wine_Normalizer_mlp=grid_MinMaxScaler_mlp.predict(X_test_wine)\n",
    "print(\"Test Error rate (Normalizer) for classifier on wine dataset:\", \n",
    "      np.mean(y_test_wine!=pred_wine_Normalizer_mlp))\n",
    "print(\"Test Error rate (Normalizer) for wine dataset:\",np.mean(y_test_wine!=pred_wine_Normalizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization accuracy (train) with MLP Classifier: 0.9925427670744421\n",
      "Accuracy (training set) of the SVM on USPS dataset (default parameters): 0.9886705655186029\n",
      "Test Error Rate (default parameters) with MLP Classifier: 0.008602150537634357\n",
      "Test Error Rate of the SVM: 0.010322580645161339\n",
      "\n",
      "\n",
      "Test Error rate (MinMaxScaler) for classifier: 0.004731182795698925\n",
      "Test Error score (MinMaxScaler) for wine dataset (SVC): 0.006021505376344086\n",
      "\n",
      "\n",
      "Test Error rate (Normalizer) for classifier on wine dataset: 0.0064516129032258064\n",
      "Test Error rate (Normalizer) for wine dataset: 0.006881720430107527\n"
     ]
    }
   ],
   "source": [
    "mlp_USPS=MLPClassifier(random_state=206)\n",
    "scores_USPS_mlp=cross_val_score(mlp_USPS,X_train_USPS,y_train_USPS)\n",
    "accuracy_USPS_mlp = np.mean(scores_USPS_mlp)\n",
    "print('Generalization accuracy (train) with MLP Classifier:',accuracy_USPS_mlp)\n",
    "print('Accuracy (training set) of the SVM on USPS dataset (default parameters):',accuracy_USPS_train)\n",
    "\n",
    "mlp_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "test_error_rate_USPS_mlp=mlp_USPS.score(X_test_USPS,y_test_USPS)\n",
    "print('Test Error Rate (default parameters) with MLP Classifier:',1-test_error_rate_USPS_mlp)\n",
    "print('Test Error Rate of the SVM:',test_error_rate_USPS)\n",
    "\n",
    "print('\\n')\n",
    "param_grid = {'mlpclassifier__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'mlpclassifier__hidden_layer_sizes': [[10],[10,10],[10,10,10]],\n",
    "              'mlpclassifier__activation':['relu','tanh']}\n",
    "\n",
    "#---- MinMaxScaler -------\n",
    "pipe_USPS_mlp_MinMaxScaler = make_pipeline(MinMaxScaler(), mlp_USPS)\n",
    "grid_MinMaxScaler_mlp_USPS = GridSearchCV(pipe_USPS_mlp_MinMaxScaler, param_grid=param_grid)\n",
    "grid_MinMaxScaler_mlp_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_MinMaxScaler_mlp=grid_MinMaxScaler_mlp_USPS.predict(X_test_USPS)\n",
    "print(\"Test Error rate (MinMaxScaler) for classifier:\", np.mean(y_test_USPS!=pred_USPS_MinMaxScaler_mlp))\n",
    "print(\"Test Error score (MinMaxScaler) for wine dataset (SVC):\", np.mean(y_test_USPS!=pred_USPS_MinMaxScaler))\n",
    "print('\\n')\n",
    "\n",
    "#----- Normalizer ------------\n",
    "pipe_USPS_Normalizer_mlp = make_pipeline(Normalizer(), mlp_USPS)\n",
    "grid_Normalizer_mlp_USPS = GridSearchCV(pipe_USPS_Normalizer_mlp, param_grid=param_grid) \n",
    "grid_Normalizer_mlp_USPS.fit(X_train_USPS,y_train_USPS)\n",
    "pred_USPS_Normalizer_mlp=grid_Normalizer_mlp_USPS.predict(X_test_USPS)\n",
    "print(\"Test Error rate (Normalizer) for classifier on wine dataset:\", \n",
    "      np.mean(y_test_USPS!=pred_USPS_Normalizer_mlp))\n",
    "print(\"Test Error rate (Normalizer) for wine dataset:\",np.mean(y_test_USPS!=pred_USPS_Normalizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Question 4: \n",
    "It was observed that the result obtained for Accuracy on training set and test error rate on test dataset for both the datasets (Wine and USPS) are almost similar meaning that the model is underfitting where training and test performance is quite similar. The model can be improved by increasing the value of C and gamma.\n",
    "\n",
    "Question 6:\n",
    "\n",
    "Normalization techiques used on Wine Data set were StandardScaler, MinMaxScaler, RobustScaler, and Normalizer.\n",
    "\n",
    "Wine Data\n",
    "\n",
    "After training the dataset and testing it on different normalisation techniques, it was observed that for:\n",
    "\n",
    "MinMaxScaler: 0.9924812030075187 (training) and 0.9777777777777777 (test score) - The performance decreased.\n",
    "\n",
    "StandardScaler: 0.9924812030075187 (training) and 1.0 (test score) - The model overfitted\n",
    "\n",
    "RobustScaler: 0.9849624060150376 (training) and 0.9777777777777777 (test score) - The model performace decreased\n",
    "\n",
    "Normalizer: 0.9097744360902256 (training) and 0.9777777777777777 (test score) - The performace of the model increased.\n",
    "\n",
    "Hence, for wine dataset Normalizer is a better normalization technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USPS Dataset\n",
    "\n",
    "After training the dataset and testing it on different normalisation techniques, it was observed that for:\n",
    "\n",
    "MinMaxScaler: 0.9939767675319088 (training) and 0.993978494623656 (test score) - The performance is underfitting.\n",
    "\n",
    "StandardScaler: 0.9954108705005019 (training) and 0.9969892473118279 (test score) - The model performance increased.\n",
    "\n",
    "RobustScaler: 0.9870930732826617 (training) and 0.9862365591397849 (test score) - The model performace decreased\n",
    "\n",
    "Normalizer: 0.9929728954538936 (training) and 0.9931182795698925 (test score) - The performace of the model is almost the same for training and test - underfitting.\n",
    "\n",
    "Hence, for USPS dataset StandardScaler is a better normalization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
